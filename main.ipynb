{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60aa9a6b",
   "metadata": {},
   "source": [
    "# Does negativity make success?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import Counter\n",
    "from helpers import text_from_ids, neg_words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import operator\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96434186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4634c7",
   "metadata": {},
   "source": [
    "#### Load the dataframe containing videos from 2019 and their features\n",
    "\n",
    "This is a big file (860 MB) so we have stored it on Google Drive. Download it from the link below and storie it as `generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet`. It was generated by the notebook `data_processing.ipynb`.\n",
    "\n",
    "https://drive.google.com/file/d/1RmVSw2MBq0Ps0dwcTQjqZsDAuivXbUaZ/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332adf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet'\n",
    "videos = pd.read_parquet(filepath, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b27129",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483673e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb853482",
   "metadata": {},
   "source": [
    "## What is negativity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbab2fa",
   "metadata": {},
   "source": [
    "### Small intro (examples with sia from vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b640b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b272e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99cad716",
   "metadata": {},
   "source": [
    "## [[Maybe put something more here]] [[Matteo]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39806742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc51fb51",
   "metadata": {},
   "source": [
    "## Regression analysis [[Djian]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6687522",
   "metadata": {},
   "source": [
    "### Overall\n",
    "\n",
    "try description and title (look at R to find what is best) [[Djian: description is better]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression(data, formula):\n",
    "    model = smf.ols(formula=formula, data=data)\n",
    "    np.random.seed(2)\n",
    "    results = model.fit()\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c307e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove videos where 'like_count' is NaN\n",
    "videos = videos[videos['like_count'].isna() == False]\n",
    "\n",
    "# Convert some rows to float\n",
    "videos['like_count'] = videos['like_count'].astype(float)\n",
    "videos['dislike_count'] = videos['dislike_count'].astype(float)\n",
    "videos['view_count'] = videos['view_count'].astype(float)\n",
    "\n",
    "# New columns for the log of the counts (+1 so that the log is always defined)\n",
    "videos['log_view_count'] = np.log(videos['view_count'] + 1)\n",
    "videos['log_like_count'] = np.log(videos['like_count'] + 1)\n",
    "videos['log_dislike_count'] = np.log(videos['dislike_count'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_factors = ['log_view_count', 'log_like_count', 'log_dislike_count']\n",
    "\n",
    "\n",
    "def regression_formula(success_factor):\n",
    "    f = f'{success_factor} ~ '\n",
    "    f += 'sia_negative_description ' \n",
    "    f += '+ sia_positive_description '\n",
    "    f += '+ sia_neutral_description '\n",
    "    return f\n",
    "\n",
    "\n",
    "formulas = [regression_formula(s) for s in success_factors]\n",
    "\n",
    "for f in formulas:\n",
    "    print(f'Regression analysis for formula \\n{f}')\n",
    "    print_regression(data=videos, formula=f)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd104b1",
   "metadata": {},
   "source": [
    "### By category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the categories\n",
    "categories = set(videos['categories'].values)\n",
    "categories.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_for_success_factor = dict()\n",
    "\n",
    "for success_factor in success_factors:\n",
    "    f = regression_formula(success_factor)\n",
    "    \n",
    "    results_params_f = dict()\n",
    "\n",
    "    for category in categories:\n",
    "        videos_category = videos[videos['categories'] == category]\n",
    "        model = smf.ols(formula=f, data=videos_category)\n",
    "        np.random.seed(2)\n",
    "        results = model.fit()\n",
    "        results_params_f[category] = pd.concat([results.params, results.pvalues], keys=['parameter', 'p-value'])\n",
    "\n",
    "    df_regression = pd.DataFrame(results_params_f).transpose()\n",
    "    \n",
    "    regression_for_success_factor[success_factor] = df_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(df_regression):\n",
    "    \n",
    "    df_reg = df_regression.copy()\n",
    "    \n",
    "    # Drop p-values and `Intercept`, remove index\n",
    "    df_reg = df_reg['parameter']\n",
    "    df_reg = df_reg.drop('Intercept', axis=1)\n",
    "    df_reg = df_reg.reset_index()\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    plt.scatter(x=df_reg['index'], y=df_reg['sia_negative_description'], marker='$:($', color='crimson', s=50)\n",
    "    plt.scatter(x=df_reg['index'], y=df_reg['sia_neutral_description'],  marker='$:|$', color='gray', s=50)\n",
    "    plt.scatter(x=df_reg['index'], y=df_reg['sia_positive_description'],  marker='$:)$', color='dodgerblue', s=50)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('log_count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regression parameters for various success factors\n",
    "\n",
    "for success_f in success_factors:\n",
    "    print(f'Linear regression for {success_f}')\n",
    "    plot_regression(regression_for_success_factor[success_f])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651825ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: seaborn plot\n",
    "'''\n",
    "# Colors for the plot\n",
    "palette_sentiment = {\n",
    "    'sia_negative_description': 'crimson',\n",
    "    'sia_neutral_description': 'gray',\n",
    "    'sia_positive_description': 'dodgerblue',\n",
    "    'Intercept': 'black'\n",
    "\n",
    "}\n",
    "\n",
    "# Drop p-values and `Intercept`, remove index\n",
    "df_regression = df_regression['parameter']\n",
    "df_regression = df_regression.drop('Intercept', axis=1)\n",
    "df_regression = df_regression.reset_index()\n",
    "\n",
    "# Convert the dataframe to long form, for seaborn plot\n",
    "df_regression_melt = df_regression.melt('index', var_name='sentiment_type', value_name='sentiment_value')\n",
    "\n",
    "# Plot\n",
    "sns.scatterplot(\n",
    "    data=df_regression_melt, \n",
    "    x='index', \n",
    "    y='sentiment_value', \n",
    "    hue='sentiment_type',\n",
    "    s=40,\n",
    "    marker='D',\n",
    "    palette=palette_sentiment,\n",
    "    #aspect=2,\n",
    "    #jitter=False,  # for vertically aligned datapoints in each category\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "'''\n",
    "' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbc23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8bcc5cc",
   "metadata": {},
   "source": [
    "## Evolution of channels with negativity [[Victor]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61609941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0119c8cd",
   "metadata": {},
   "source": [
    "## What does successful negativity look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714bfff6",
   "metadata": {},
   "source": [
    "### Most used words: the vocabulary of videos that are negative and successful (for different categories) [[Maj]]\n",
    "\n",
    "Make 'histogram' of words in title/desc for videos that are very negative and have lots of success (maybe do it for each category). Example:\n",
    "\n",
    "https://ldrame21.github.io/metoo-media-impact/#data-story-title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd89f1f",
   "metadata": {},
   "source": [
    "#### What is a negative and successful video?\n",
    "\n",
    "A negative video is the one with sia_negative_description>= 0.4. \n",
    "\n",
    "A successful video is the one with number of views is above the average number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = videos.copy()\n",
    "df_videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_count = df_videos['view_count'].mean()\n",
    "print(mean_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select negative and successful videos\n",
    "df_filtered = df_videos[(df_videos['sia_negative_description'] >= 0.4) & (df_videos['view_count'] >= 80000)]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1053abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'generated/2019/2019_videos.csv'\n",
    "video_ids = set(df_filtered['display_id'])\n",
    "df_title_des= text_from_ids(video_ids, data_path) #contains display_id, title, description and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e73b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge both dataframes\n",
    "df_combined = pd.merge(df_filtered, df_title_des, on=\"display_id\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f05afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove stopwords from titles \n",
    "def remove_stopwords(df):\n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned['tokens'] = df_cleaned['tags'].apply(lambda title: title.split())\n",
    "    stop_words = stopwords.words('english')\n",
    "    df_cleaned['tokens'] = df_cleaned['tokens'].apply(lambda tokens: [token for token in tokens if token.lower() not in stop_words])\n",
    "    return df_cleaned\n",
    "\n",
    "df_cleaned = remove_stopwords(df_combined)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea531c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the 5 most successful categories based on view_count\n",
    "grouped = df_cleaned.groupby(\"categories\")\n",
    "most_successful = {}\n",
    "for name, group in grouped:\n",
    "    most_successful[name] = group['view_count'].mean()\n",
    "sorted_dict = sorted(most_successful.items(), key=operator.itemgetter(1), reverse=True)[:5]\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b1c96",
   "metadata": {},
   "source": [
    "## Most common negative words in the most successful categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2b503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the most common words in the most 5 successful categories \n",
    "common_words_with_freq = {}\n",
    "\n",
    "categorie_groups = df_cleaned.groupby(\"categories\")\n",
    "for name, group in categorie_groups:\n",
    "    flattened = [val for sublist in group['tokens'].tolist() for val in sublist]\n",
    "    common_words_with_freq[name] = Counter(flattened).most_common(100)\n",
    "#convert the dict to a dataframe   \n",
    "L = [(k, *t) for k, v in common_words_with_freq.items() for t in v]\n",
    "df_success = pd.DataFrame(L, columns=['categories','common_words','frequency'])\n",
    "df_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_all = pd.DataFrame(common_words_with_freq.items(), columns=['categories', 'most_common_words'])\n",
    "df_success_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34aed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_success.groupby(\"categories\")\n",
    "for name, group in grouped:\n",
    "    group_words = [item.lower() for item in grouped['common_words'].get_group(name).tolist()]\n",
    "    #group_neg_words = list(set(group_words) & neg_set)\n",
    "    if(len(group_words) != 0):\n",
    "        group_freq = grouped['frequency'].get_group(name).tolist()\n",
    "        data = dict(zip(group_words, group_freq))\n",
    "        wc = WordCloud(width=800, height=400, max_words=200).generate_from_frequencies(data)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(name)\n",
    "        plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c1f3f",
   "metadata": {},
   "source": [
    "# What topics appear the most in negative and successful videos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont forget the put the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58037203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import *\n",
    "import re \n",
    "import gensim\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sucessful and negative videos: df_cleaned\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c277d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove urls\n",
    "def remove_url(text):\n",
    "    return re.sub(r'https?:\\S*','',text)\n",
    "df_cleaned.description = df_cleaned.description.apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988aa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mentions and tags\n",
    "def remove_mentions_and_tags(text):\n",
    "    text = re.sub(r'@\\S*','',text)\n",
    "    return re.sub(r'#\\S*','',text)\n",
    "df_cleaned.description = df_cleaned.description.apply(remove_mentions_and_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    corpus = []\n",
    "    lem = WordNetLemmatizer() # For Lemmatization\n",
    "    for news in df['description']:\n",
    "        words=[w for w in nltk.tokenize.word_tokenize(news) if (w not in stopwords)] # word_tokenize function tokenizes text on each word by default\n",
    "        words=[lem.lemmatize(w) for w in words if len(w)>2]\n",
    "        corpus.append(words)\n",
    "    return corpus\n",
    "\n",
    "# Apply this function on our data frame\n",
    "corpus = preprocessing(df_cleaned)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to gensim dictionary\n",
    "dic = gensim.corpora.Dictionary(corpus) \n",
    "bow_corpus = [dic.doc2bow(doc) for doc in corpus]\n",
    "pickle.dump(bow_corpus, open('corpus.pkl', 'wb'))\n",
    "dic.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14310453",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                   num_topics = 15,\n",
    "                                    id2word = dic,\n",
    "                                      passes = 10,\n",
    "                                      workers = 2)\n",
    "lda_model.save('model15.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92846c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print words occuring in each of the topics as we iterate through them\n",
    "for idx, topic in lda_model.print_topics(num_words=50):    \n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6bb31d",
   "metadata": {},
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35aebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b87f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dictionary and corpus files we saved earlier\n",
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "\n",
    "# Loading the num_of_topics = 2 model we saved earlier\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model15.gensim')\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, bow_corpus, dic, sort_topics=False)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4f14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5ea01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
