{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790626ee",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b46fe2",
   "metadata": {},
   "source": [
    "#### Load the dataframe containing videos from 2019 and their features\n",
    "\n",
    "This is a big file (860 MB) so we have stored it on Google Drive. Download it from the link below and storie it as `generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet`. It was generated by the notebook `data_processing.ipynb`.\n",
    "\n",
    "https://drive.google.com/file/d/1RmVSw2MBq0Ps0dwcTQjqZsDAuivXbUaZ/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet'\n",
    "videos = pd.read_parquet(filepath, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f293302",
   "metadata": {},
   "source": [
    "We check that each video has a unique identifier (column `display_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1907c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.set_index(videos['display_id']).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b4068",
   "metadata": {},
   "source": [
    "There are videos with NaN values in some field but we do not remove them as it is not needed for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nan = len(videos) - len(videos.dropna())\n",
    "\n",
    "print(f'There are {nb_nan} videos with a NaN field ({nb_nan / len(videos) :.1%} of the total).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489642b9",
   "metadata": {},
   "source": [
    "What fraction of the dataset do videos from 2019 respresent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_videos_2019 = len(videos)\n",
    "nb_videos_total = 73e6\n",
    "\n",
    "print(f'Fractions of videos that are from 2019: {(nb_videos_2019 / nb_videos_total):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49f74a",
   "metadata": {},
   "source": [
    "What columns do we have in our dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dd9a1",
   "metadata": {},
   "source": [
    "Fields that were already present in the original dataset from Zenodo:\n",
    "\n",
    "- `categories`\n",
    "- `channel_id`\n",
    "- `crawl_date`\n",
    "- `dislike_count`\n",
    "- `display_id`\n",
    "- `duration`\n",
    "- `like_count`\n",
    "- `upload_date`\n",
    "- `view_count`\n",
    "\n",
    "Features we have created:\n",
    "\n",
    "- Number of exclamation marks in the title (or the description) of the video: `count_excl_marks_title`, `count_excl_marks_description`.\n",
    "\n",
    "- Number of words in all caps in the title (or the description) of the video: `count_upper_words_title`, `count_upper_words_description`.\n",
    "\n",
    "- Number of negative emojis in the title (or the description) of the video: `count_negative_emojis_title`, `count_negative_emojis_description`.\n",
    "\n",
    "- Number of (negative) words in the title (or the description) of the video: `count_words_title`, `count_negative_words_title`, `count_words_description`, `count_negative_words_description`.\n",
    "\n",
    "- Intensity score in the title (or the description) of the sentiment 'negative', 'neutral' and 'positive' according to VADER (plus compund): `sia_negative_title`, `sia_neutral_title`, `sia_positive_title`, `sia_compound_title`, `sia_negative_description`, `sia_neutral_description`, `sia_positive_description`, `sia_compound_description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67dac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7045f",
   "metadata": {},
   "source": [
    "Let us look at some basic statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7427f",
   "metadata": {},
   "source": [
    "### Look at the distribution of the features\n",
    "\n",
    "We look at ratios since what matters for the negativity is the fraction of negative words (etc.) and not the absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the field types (this will help us plot the data)\n",
    "\n",
    "type_text_desc = ['description'] * len(videos)\n",
    "type_text_title = ['title'] * len(videos)\n",
    "type_text = np.concatenate((type_text_desc, type_text_title), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8dedd",
   "metadata": {},
   "source": [
    "#### Typography of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_excl_title = videos['count_excl_marks_title'] / videos['count_words_title']\n",
    "ratio_excl_description = videos['count_excl_marks_description'] / videos['count_words_description']\n",
    "ratio_excl = np.concatenate((ratio_excl_description, ratio_excl_title), None)\n",
    "# Note: The ratio nb_exclamation_marks / nb_words is maybe not the best choice, we might change it later on.\n",
    "\n",
    "ratio_upper_title = videos['count_upper_words_title']/videos['count_words_title']\n",
    "ratio_upper_description = videos['count_upper_words_description']/videos['count_words_description']\n",
    "ratio_upper_words = np.concatenate((ratio_upper_description, ratio_upper_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "ratio_typo = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of exclamation marks (out of words)': ratio_excl,\n",
    "    'Fraction of upper words': ratio_upper_words,\n",
    "})\n",
    "\n",
    "sns.histplot(ratio_typo, x='Fraction of exclamation marks (out of words)', bins=50, hue=\"Field\", element=\"step\", ax=axes[1]).set(yscale ='log')\n",
    "sns.histplot(ratio_typo, x='Fraction of upper words', bins=50, hue=\"Field\", element=\"step\", ax=axes[0]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Typographic features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaa6c0",
   "metadata": {},
   "source": [
    "#### Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_emojis_title = videos['count_negative_emojis_title'] / videos['count_words_title']\n",
    "ratio_emojis_description = videos['count_negative_emojis_description'] / videos['count_words_description']\n",
    "ratio_emojis = np.concatenate((ratio_emojis_description, ratio_emojis_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_emojis = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative emojis (out of words)': ratio_emojis\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_emojis, x='Fraction of negative emojis (out of words)', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative emojis')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0a2e5",
   "metadata": {},
   "source": [
    "#### Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_neg_words_title = videos['count_negative_words_title']/videos['count_words_title']\n",
    "ratio_neg_words_description = videos['count_negative_words_description']/videos['count_words_description']\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_neg_words = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative words': np.concatenate((ratio_neg_words_description, ratio_neg_words_title), None)\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_neg_words, x='Fraction of negative words', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d8762",
   "metadata": {},
   "source": [
    "#### Sentiment intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16,12))\n",
    "\n",
    "sentiment = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Negative sentiment': np.concatenate((videos['sia_negative_description'], videos['sia_negative_title']), None),\n",
    "    'Positive sentiment': np.concatenate((videos['sia_positive_description'], videos['sia_positive_title']), None),\n",
    "    'Neutral sentiment': np.concatenate((videos['sia_neutral_description'], videos['sia_neutral_title']), None),\n",
    "    'Compound': np.concatenate((videos['sia_compound_description'], videos['sia_compound_title']), None)\n",
    "\n",
    "})\n",
    "\n",
    "sns.histplot(sentiment, x='Negative sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Positive sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 1]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Neutral sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Compound', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 1]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Sentiment intensity (Vader)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d5805",
   "metadata": {},
   "source": [
    "#### Combine timeseries and videos to get ratios "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f008cd",
   "metadata": {},
   "source": [
    "For each video, we want to get the ratio of like by subscribers of the channel that uploaded the video. As well as the ratio of dislike by subscribers, and views by total views of the channel. To do this, we need to merge the timeseries dataframe and the videos features dataframe on the date, grouping them by channel id.\n",
    "\n",
    "Since we want to get the most accurate number of subscribers at the time of upload of the given video, we perform a nearest time merge, where we only merge on the entry of timeseries that has the closest datetime to the upload date, given a tolerance of one week (as the timeseries analysis was conducted per week). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc8f85",
   "metadata": {},
   "source": [
    "First step is to load the timeseries and filter out the years that are not used in our study (here we only keep 2019 for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabdaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_timeseries = pd.read_csv(\"data/df_timeseries_en.tsv\", sep=\"\\t\")\n",
    "df_timeseries_2019 = df_timeseries[pd.to_datetime(df_timeseries[\"datetime\"]).dt.year == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries_2019.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8817b",
   "metadata": {},
   "source": [
    "Then, we rename the columns accordingly for the merge asof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53634cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_timeseries_2019[\"datetime\"] = pd.to_datetime(df_timeseries_2019['datetime'])\n",
    "df_timeseries_2019.rename({\"datetime\": \"nearest_time\"}, axis=1, inplace=True)\n",
    "videos.rename({\"upload_date\": \"nearest_time\"}, axis=1, inplace=True)\n",
    "df_timeseries_2019.rename({\"channel\": \"channel_id\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e37827",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_on_date_by_channel = pd.merge_asof(videos.sort_values(\"nearest_time\"),df_timeseries_2019.sort_values(\"nearest_time\"),on=\"nearest_time\",by=\"channel_id\",allow_exact_matches=True,direction=\"nearest\",tolerance=pd.Timedelta(1,unit=\"W\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22d8d9",
   "metadata": {},
   "source": [
    "Since some videos were uploaded by channels that are not in the timeseries, we end up with NaN values. We decided to remove the rows that have these NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fad95d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# approx 1M missing values (channels that are in metadata but not in timeseries)\n",
    "videos_on_date_by_channel.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69b118",
   "metadata": {},
   "source": [
    "We create new columns for the ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28549086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratio_column(df, new_col,col1,col2):\n",
    "        df[new_col] = df[col1]/df[col2]\n",
    "\n",
    "create_ratio_column(videos_on_date_by_channel,\"like_count_by_subs\",\"like_count\",\"subs\")\n",
    "create_ratio_column(videos_on_date_by_channel,\"dislike_count_by_subs\",\"dislike_count\",\"subs\")\n",
    "create_ratio_column(videos_on_date_by_channel,\"view_count_by_channel_views\",\"view_count\",\"views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9622d86",
   "metadata": {},
   "source": [
    "Let's now plot the distribution of the number of views between all the videos and the distribution of the number of subscribers between all the channels. In fact, knowing this information will helps us decide what kind of normalization should be use in the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19062f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "videos_on_date_by_channel = videos_on_date_by_channel[videos_on_date_by_channel[\"views\"] > 0]\n",
    "videos_on_date_by_channel = videos_on_date_by_channel[videos_on_date_by_channel[\"subs\"] > 0]\n",
    "\n",
    "sns.histplot(videos_on_date_by_channel, x=\"views\", bins=50, element=\"step\", ax=axes[0])\n",
    "sns.histplot(videos_on_date_by_channel, x=\"subs\", bins=50, element=\"step\", ax=axes[1])\n",
    "\n",
    "axes[0].set(yscale ='log')\n",
    "axes[0].set_title('Distribution of the number of views between all the videos')\n",
    "\n",
    "axes[1].set(yscale ='log')\n",
    "axes[1].set_title('Distribution of the number of subscribers between all the channels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33768294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
