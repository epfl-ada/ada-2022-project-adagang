{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d566d3c",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd113633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90420f7d",
   "metadata": {},
   "source": [
    "#### Load the dataframe containing videos from 2019 and their features\n",
    "\n",
    "This is a big file (860 MB) so we have stored it on Google Drive. Download it from the link below and storie it as `generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet`. It was generated by the notebook `data_processing.ipynb`.\n",
    "\n",
    "https://drive.google.com/file/d/1RmVSw2MBq0Ps0dwcTQjqZsDAuivXbUaZ/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd85343",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet'\n",
    "videos = pd.read_parquet(filepath, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa418a8e",
   "metadata": {},
   "source": [
    "What fraction of the dataset do videos from 2019 respresent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa393a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_videos_2019 = len(videos)\n",
    "nb_videos_total = 73e6\n",
    "\n",
    "print(f'Fractions of videos that are from 2019: {(nb_videos_2019 / nb_videos_total):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee350c",
   "metadata": {},
   "source": [
    "What columns do we have in our dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e2536",
   "metadata": {},
   "source": [
    "Fields that were already present in the original dataset from Zenodo:\n",
    "\n",
    "- `categories`\n",
    "- `channel_id`\n",
    "- `crawl_date`\n",
    "- `dislike_count`\n",
    "- `display_id`\n",
    "- `duration`\n",
    "- `like_count`\n",
    "- `upload_date`\n",
    "- `view_count`\n",
    "\n",
    "Features we have created:\n",
    "\n",
    "- Number of exclamation marks in the title (or the description) of the video: `count_excl_marks_title`, `count_excl_marks_description`.\n",
    "\n",
    "- Number of words in all caps in the title (or the description) of the video: `count_upper_words_title`, `count_upper_words_description`.\n",
    "\n",
    "- Number of negative emojis in the title (or the description) of the video: `count_negative_emojis_title`, `count_negative_emojis_description`.\n",
    "\n",
    "- Number of (negative) words in the title (or the description) of the video: `count_words_title`, `count_negative_words_title`, `count_words_description`, `count_negative_words_description`.\n",
    "\n",
    "- Intensity score in the title (or the description) of the sentiment 'negative', 'neutral' and 'positive' according to VADER (plus compund): `sia_negative_title`, `sia_neutral_title`, `sia_positive_title`, `sia_compound_title`, `sia_negative_description`, `sia_neutral_description`, `sia_positive_description`, `sia_compound_description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18d266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0333449",
   "metadata": {},
   "source": [
    "### Look at the distribution of the features\n",
    "\n",
    "We look at ratios since what matters for the negativity is the fraction of negative words (etc.) and not the absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the field types (this will help us plot the data)\n",
    "\n",
    "type_text_desc = ['description'] * len(videos)\n",
    "type_text_title = ['title'] * len(videos)\n",
    "type_text = np.concatenate((type_text_desc, type_text_title), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c64668",
   "metadata": {},
   "source": [
    "#### Typography of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb77d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_excl_title = videos['count_excl_marks_title'] / videos['count_words_title']\n",
    "ratio_excl_description = videos['count_excl_marks_description'] / videos['count_words_description']\n",
    "ratio_excl = np.concatenate((ratio_excl_description, ratio_excl_title), None)\n",
    "\n",
    "ratio_upper_title = videos['count_upper_words_title']/videos['count_words_title']\n",
    "ratio_upper_description = videos['count_upper_words_description']/videos['count_words_description']\n",
    "ratio_upper_words = np.concatenate((ratio_upper_description, ratio_upper_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "ratio_typo = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of exclamation marks (out of words)': ratio_excl,\n",
    "    'Fraction of upper words': ratio_upper_words,\n",
    "})\n",
    "\n",
    "sns.histplot(ratio_typo, x='Fraction of exclamation marks (out of words)', bins=50, hue=\"Field\", element=\"step\", ax=axes[1]).set(yscale ='log')\n",
    "sns.histplot(ratio_typo, x='Fraction of upper words', bins=50, hue=\"Field\", element=\"step\", ax=axes[0]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Typographic features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66fdde",
   "metadata": {},
   "source": [
    "#### Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_emojis_title = videos['count_negative_emojis_title'] / videos['count_words_title']\n",
    "ratio_emojis_description = videos['count_negative_emojis_description'] / videos['count_words_description']\n",
    "ratio_emojis = np.concatenate((ratio_emojis_description, ratio_emojis_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_emojis = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative emojis (out of words)': ratio_emojis\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_emojis, x='Fraction of negative emojis (out of words)', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative emojis')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13f447",
   "metadata": {},
   "source": [
    "#### Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_neg_words_title = videos['count_negative_words_title']/videos['count_words_title']\n",
    "ratio_neg_words_description = videos['count_negative_words_description']/videos['count_words_description']\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_neg_words = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative words': np.concatenate((ratio_neg_words_description, ratio_neg_words_title), None)\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_neg_words, x='Fraction of negative words', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03035b0",
   "metadata": {},
   "source": [
    "#### Sentiment intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16,12))\n",
    "\n",
    "sentiment = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Negative sentiment': np.concatenate((videos['sia_negative_description'], videos['sia_negative_title']), None),\n",
    "    'Positive sentiment': np.concatenate((videos['sia_positive_description'], videos['sia_positive_title']), None),\n",
    "    'Neutral sentiment': np.concatenate((videos['sia_neutral_description'], videos['sia_neutral_title']), None),\n",
    "    'Compound': np.concatenate((videos['sia_compound_description'], videos['sia_compound_title']), None)\n",
    "\n",
    "})\n",
    "\n",
    "sns.histplot(sentiment, x='Negative sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Positive sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 1]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Neutral sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Compound', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 1]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Sentiment intensity (Vader)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e218f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
