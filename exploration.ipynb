{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790626ee",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfee3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from helpers.py import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b46fe2",
   "metadata": {},
   "source": [
    "#### Load the dataframe containing videos from 2019 and their features\n",
    "\n",
    "This is a big file (860 MB) so we have stored it on Google Drive. Download it from the link below and storie it as `generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet`. It was generated by the notebook `data_processing.ipynb`.\n",
    "\n",
    "https://drive.google.com/file/d/1RmVSw2MBq0Ps0dwcTQjqZsDAuivXbUaZ/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'generated/2019/2019_videos_Typo_Emojis_NegWords_Sentiment_title_desc.parquet'\n",
    "videos = pd.read_parquet(filepath, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f293302",
   "metadata": {},
   "source": [
    "We check that each video has a unique identifier (column `display_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1907c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.set_index(videos['display_id']).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b4068",
   "metadata": {},
   "source": [
    "There are videos with NaN values in some field but we do not remove them as it is not needed for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11a9329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 290620 videos with a NaN field (2.3% of the total).\n"
     ]
    }
   ],
   "source": [
    "nb_nan = len(videos) - len(videos.dropna())\n",
    "\n",
    "print(f'There are {nb_nan} videos with a NaN field ({nb_nan / len(videos) :.1%} of the total).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489642b9",
   "metadata": {},
   "source": [
    "What fraction of the dataset do videos from 2019 respresent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cca2f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions of videos that are from 2019: 17.4%\n"
     ]
    }
   ],
   "source": [
    "nb_videos_2019 = len(videos)\n",
    "nb_videos_total = 73e6\n",
    "\n",
    "print(f'Fractions of videos that are from 2019: {(nb_videos_2019 / nb_videos_total):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49f74a",
   "metadata": {},
   "source": [
    "What columns do we have in our dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dd9a1",
   "metadata": {},
   "source": [
    "Fields that were already present in the original dataset from Zenodo:\n",
    "\n",
    "- `categories`\n",
    "- `channel_id`\n",
    "- `crawl_date`\n",
    "- `dislike_count`\n",
    "- `display_id`\n",
    "- `duration`\n",
    "- `like_count`\n",
    "- `upload_date`\n",
    "- `view_count`\n",
    "\n",
    "Features we have created:\n",
    "\n",
    "- Number of exclamation marks in the title (or the description) of the video: `count_excl_marks_title`, `count_excl_marks_description`.\n",
    "\n",
    "- Number of words in all caps in the title (or the description) of the video: `count_upper_words_title`, `count_upper_words_description`.\n",
    "\n",
    "- Number of negative emojis in the title (or the description) of the video: `count_negative_emojis_title`, `count_negative_emojis_description`.\n",
    "\n",
    "- Number of (negative) words in the title (or the description) of the video: `count_words_title`, `count_negative_words_title`, `count_words_description`, `count_negative_words_description`.\n",
    "\n",
    "- Intensity score in the title (or the description) of the sentiment 'negative', 'neutral' and 'positive' according to VADER (plus compund): `sia_negative_title`, `sia_neutral_title`, `sia_positive_title`, `sia_compound_title`, `sia_negative_description`, `sia_neutral_description`, `sia_positive_description`, `sia_compound_description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b67dac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12723124 entries, 0 to 12723123\n",
      "Data columns (total 27 columns):\n",
      " #   Column                             Dtype         \n",
      "---  ------                             -----         \n",
      " 0   categories                         object        \n",
      " 1   channel_id                         object        \n",
      " 2   crawl_date                         datetime64[ns]\n",
      " 3   dislike_count                      Int32         \n",
      " 4   display_id                         object        \n",
      " 5   duration                           object        \n",
      " 6   like_count                         Int64         \n",
      " 7   upload_date                        datetime64[ns]\n",
      " 8   view_count                         Int64         \n",
      " 9   count_words_title                  int64         \n",
      " 10  count_negative_words_title         int64         \n",
      " 11  count_words_description            int64         \n",
      " 12  count_negative_words_description   int64         \n",
      " 13  sia_negative_title                 float64       \n",
      " 14  sia_neutral_title                  float64       \n",
      " 15  sia_positive_title                 float64       \n",
      " 16  sia_compound_title                 float64       \n",
      " 17  count_negative_emojis_title        int64         \n",
      " 18  count_upper_words_title            int64         \n",
      " 19  count_excl_marks_title             int64         \n",
      " 20  count_upper_words_description      int64         \n",
      " 21  count_excl_marks_description       int64         \n",
      " 22  count_negative_emojis_description  int64         \n",
      " 23  sia_negative_description           float64       \n",
      " 24  sia_neutral_description            float64       \n",
      " 25  sia_positive_description           float64       \n",
      " 26  sia_compound_description           float64       \n",
      "dtypes: Int32(1), Int64(2), datetime64[ns](2), float64(8), int64(10), object(4)\n",
      "memory usage: 2.5+ GB\n"
     ]
    }
   ],
   "source": [
    "videos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7045f",
   "metadata": {},
   "source": [
    "Let us look at some basic statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186e7bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>view_count</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_negative_words_title</th>\n",
       "      <th>count_words_description</th>\n",
       "      <th>count_negative_words_description</th>\n",
       "      <th>sia_negative_title</th>\n",
       "      <th>sia_neutral_title</th>\n",
       "      <th>sia_positive_title</th>\n",
       "      <th>...</th>\n",
       "      <th>count_negative_emojis_title</th>\n",
       "      <th>count_upper_words_title</th>\n",
       "      <th>count_excl_marks_title</th>\n",
       "      <th>count_upper_words_description</th>\n",
       "      <th>count_excl_marks_description</th>\n",
       "      <th>count_negative_emojis_description</th>\n",
       "      <th>sia_negative_description</th>\n",
       "      <th>sia_neutral_description</th>\n",
       "      <th>sia_positive_description</th>\n",
       "      <th>sia_compound_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12432558.0</td>\n",
       "      <td>12432558.0</td>\n",
       "      <td>12723002.0</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "      <td>1.272312e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.124659</td>\n",
       "      <td>1391.32889</td>\n",
       "      <td>76925.3421</td>\n",
       "      <td>9.705946e+00</td>\n",
       "      <td>2.296305e-01</td>\n",
       "      <td>6.695788e+01</td>\n",
       "      <td>9.016759e-01</td>\n",
       "      <td>5.931906e-02</td>\n",
       "      <td>8.559609e-01</td>\n",
       "      <td>8.458568e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.667093e-04</td>\n",
       "      <td>1.458606e+00</td>\n",
       "      <td>1.775470e-01</td>\n",
       "      <td>4.513601e+00</td>\n",
       "      <td>1.178725e+00</td>\n",
       "      <td>6.151005e-04</td>\n",
       "      <td>3.275325e-02</td>\n",
       "      <td>8.174059e-01</td>\n",
       "      <td>1.124074e-01</td>\n",
       "      <td>4.532799e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1499.490853</td>\n",
       "      <td>15057.447047</td>\n",
       "      <td>1280569.519551</td>\n",
       "      <td>3.726376e+00</td>\n",
       "      <td>5.057305e-01</td>\n",
       "      <td>6.315216e+01</td>\n",
       "      <td>1.701385e+00</td>\n",
       "      <td>1.318519e-01</td>\n",
       "      <td>1.918755e-01</td>\n",
       "      <td>1.517358e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.171093e-02</td>\n",
       "      <td>2.508519e+00</td>\n",
       "      <td>5.977196e-01</td>\n",
       "      <td>9.724559e+00</td>\n",
       "      <td>3.270381e+00</td>\n",
       "      <td>3.166011e-02</td>\n",
       "      <td>6.034231e-02</td>\n",
       "      <td>1.961744e-01</td>\n",
       "      <td>1.016459e-01</td>\n",
       "      <td>5.244420e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.170000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.740000e-01</td>\n",
       "      <td>2.400000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.530000e-01</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>6.369000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>13781.0</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.580000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.400000e-02</td>\n",
       "      <td>9.270000e-01</td>\n",
       "      <td>1.680000e-01</td>\n",
       "      <td>9.256000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1555392.0</td>\n",
       "      <td>11046932.0</td>\n",
       "      <td>1578557905.0</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>6.000000e+02</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>4.260000e+02</td>\n",
       "      <td>4.976000e+03</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dislike_count    like_count      view_count  count_words_title  \\\n",
       "count     12432558.0    12432558.0      12723002.0       1.272312e+07   \n",
       "mean       73.124659    1391.32889      76925.3421       9.705946e+00   \n",
       "std      1499.490853  15057.447047  1280569.519551       3.726376e+00   \n",
       "min              0.0           0.0             0.0       1.000000e+00   \n",
       "25%              0.0           8.0           418.0       7.000000e+00   \n",
       "50%              3.0          57.0          2350.0       1.000000e+01   \n",
       "75%             15.0         355.0         13781.0       1.200000e+01   \n",
       "max        1555392.0    11046932.0    1578557905.0       3.400000e+01   \n",
       "\n",
       "       count_negative_words_title  count_words_description  \\\n",
       "count                1.272312e+07             1.272312e+07   \n",
       "mean                 2.296305e-01             6.695788e+01   \n",
       "std                  5.057305e-01             6.315216e+01   \n",
       "min                  0.000000e+00             1.000000e+00   \n",
       "25%                  0.000000e+00             2.200000e+01   \n",
       "50%                  0.000000e+00             4.900000e+01   \n",
       "75%                  0.000000e+00             9.200000e+01   \n",
       "max                  7.000000e+00             6.000000e+02   \n",
       "\n",
       "       count_negative_words_description  sia_negative_title  \\\n",
       "count                      1.272312e+07        1.272312e+07   \n",
       "mean                       9.016759e-01        5.931906e-02   \n",
       "std                        1.701385e+00        1.318519e-01   \n",
       "min                        0.000000e+00        0.000000e+00   \n",
       "25%                        0.000000e+00        0.000000e+00   \n",
       "50%                        0.000000e+00        0.000000e+00   \n",
       "75%                        1.000000e+00        0.000000e+00   \n",
       "max                        5.900000e+01        1.000000e+00   \n",
       "\n",
       "       sia_neutral_title  sia_positive_title  ...  \\\n",
       "count       1.272312e+07        1.272312e+07  ...   \n",
       "mean        8.559609e-01        8.458568e-02  ...   \n",
       "std         1.918755e-01        1.517358e-01  ...   \n",
       "min         0.000000e+00        0.000000e+00  ...   \n",
       "25%         7.170000e-01        0.000000e+00  ...   \n",
       "50%         1.000000e+00        0.000000e+00  ...   \n",
       "75%         1.000000e+00        1.580000e-01  ...   \n",
       "max         1.000000e+00        1.000000e+00  ...   \n",
       "\n",
       "       count_negative_emojis_title  count_upper_words_title  \\\n",
       "count                 1.272312e+07             1.272312e+07   \n",
       "mean                  4.667093e-04             1.458606e+00   \n",
       "std                   2.171093e-02             2.508519e+00   \n",
       "min                   0.000000e+00             0.000000e+00   \n",
       "25%                   0.000000e+00             0.000000e+00   \n",
       "50%                   0.000000e+00             0.000000e+00   \n",
       "75%                   0.000000e+00             2.000000e+00   \n",
       "max                   2.000000e+00             2.400000e+01   \n",
       "\n",
       "       count_excl_marks_title  count_upper_words_description  \\\n",
       "count            1.272312e+07                   1.272312e+07   \n",
       "mean             1.775470e-01                   4.513601e+00   \n",
       "std              5.977196e-01                   9.724559e+00   \n",
       "min              0.000000e+00                   0.000000e+00   \n",
       "25%              0.000000e+00                   0.000000e+00   \n",
       "50%              0.000000e+00                   1.000000e+00   \n",
       "75%              0.000000e+00                   4.000000e+00   \n",
       "max              9.000000e+01                   4.260000e+02   \n",
       "\n",
       "       count_excl_marks_description  count_negative_emojis_description  \\\n",
       "count                  1.272312e+07                       1.272312e+07   \n",
       "mean                   1.178725e+00                       6.151005e-04   \n",
       "std                    3.270381e+00                       3.166011e-02   \n",
       "min                    0.000000e+00                       0.000000e+00   \n",
       "25%                    0.000000e+00                       0.000000e+00   \n",
       "50%                    0.000000e+00                       0.000000e+00   \n",
       "75%                    1.000000e+00                       0.000000e+00   \n",
       "max                    4.976000e+03                       1.400000e+01   \n",
       "\n",
       "       sia_negative_description  sia_neutral_description  \\\n",
       "count              1.272312e+07             1.272312e+07   \n",
       "mean               3.275325e-02             8.174059e-01   \n",
       "std                6.034231e-02             1.961744e-01   \n",
       "min                0.000000e+00             0.000000e+00   \n",
       "25%                0.000000e+00             7.740000e-01   \n",
       "50%                0.000000e+00             8.530000e-01   \n",
       "75%                4.400000e-02             9.270000e-01   \n",
       "max                1.000000e+00             1.000000e+00   \n",
       "\n",
       "       sia_positive_description  sia_compound_description  \n",
       "count              1.272312e+07              1.272312e+07  \n",
       "mean               1.124074e-01              4.532799e-01  \n",
       "std                1.016459e-01              5.244420e-01  \n",
       "min                0.000000e+00             -1.000000e+00  \n",
       "25%                2.400000e-02              0.000000e+00  \n",
       "50%                1.000000e-01              6.369000e-01  \n",
       "75%                1.680000e-01              9.256000e-01  \n",
       "max                1.000000e+00              1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7427f",
   "metadata": {},
   "source": [
    "### Look at the distribution of the features\n",
    "\n",
    "We look at ratios since what matters for the negativity is the fraction of negative words (etc.) and not the absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a7e14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the field types (this will help us plot the data)\n",
    "\n",
    "type_text_desc = ['description'] * len(videos)\n",
    "type_text_title = ['title'] * len(videos)\n",
    "type_text = np.concatenate((type_text_desc, type_text_title), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8dedd",
   "metadata": {},
   "source": [
    "#### Typography of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_excl_title = videos['count_excl_marks_title'] / videos['count_words_title']\n",
    "ratio_excl_description = videos['count_excl_marks_description'] / videos['count_words_description']\n",
    "ratio_excl = np.concatenate((ratio_excl_description, ratio_excl_title), None)\n",
    "\n",
    "ratio_upper_title = videos['count_upper_words_title']/videos['count_words_title']\n",
    "ratio_upper_description = videos['count_upper_words_description']/videos['count_words_description']\n",
    "ratio_upper_words = np.concatenate((ratio_upper_description, ratio_upper_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "ratio_typo = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of exclamation marks (out of words)': ratio_excl,\n",
    "    'Fraction of upper words': ratio_upper_words,\n",
    "})\n",
    "\n",
    "sns.histplot(ratio_typo, x='Fraction of exclamation marks (out of words)', bins=50, hue=\"Field\", element=\"step\", ax=axes[1]).set(yscale ='log')\n",
    "sns.histplot(ratio_typo, x='Fraction of upper words', bins=50, hue=\"Field\", element=\"step\", ax=axes[0]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Typographic features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaa6c0",
   "metadata": {},
   "source": [
    "#### Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_emojis_title = videos['count_negative_emojis_title'] / videos['count_words_title']\n",
    "ratio_emojis_description = videos['count_negative_emojis_description'] / videos['count_words_description']\n",
    "ratio_emojis = np.concatenate((ratio_emojis_description, ratio_emojis_title), None)\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_emojis = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative emojis (out of words)': ratio_emojis\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_emojis, x='Fraction of negative emojis (out of words)', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative emojis')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0a2e5",
   "metadata": {},
   "source": [
    "#### Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratios\n",
    "\n",
    "ratio_neg_words_title = videos['count_negative_words_title']/videos['count_words_title']\n",
    "ratio_neg_words_description = videos['count_negative_words_description']/videos['count_words_description']\n",
    "\n",
    "\n",
    "# Plot\n",
    "\n",
    "ratio_neg_words = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Fraction of negative words': np.concatenate((ratio_neg_words_description, ratio_neg_words_title), None)\n",
    "})\n",
    "\n",
    "fig = plt.subplot()\n",
    "sns.histplot(ratio_neg_words, x='Fraction of negative words', bins=50, hue=\"Field\", element=\"step\").set(yscale ='log')\n",
    "\n",
    "fig.set_title('Negative words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d8762",
   "metadata": {},
   "source": [
    "#### Sentiment intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16,12))\n",
    "\n",
    "sentiment = pd.DataFrame({\n",
    "    'Field': type_text,\n",
    "    'Negative sentiment': np.concatenate((videos['sia_negative_description'], videos['sia_negative_title']), None),\n",
    "    'Positive sentiment': np.concatenate((videos['sia_positive_description'], videos['sia_positive_title']), None),\n",
    "    'Neutral sentiment': np.concatenate((videos['sia_neutral_description'], videos['sia_neutral_title']), None),\n",
    "    'Compound': np.concatenate((videos['sia_compound_description'], videos['sia_compound_title']), None)\n",
    "\n",
    "})\n",
    "\n",
    "sns.histplot(sentiment, x='Negative sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Positive sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[0, 1]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Neutral sentiment', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 0]).set(yscale ='log')\n",
    "sns.histplot(sentiment, x='Compound', bins=50, hue=\"Field\", element=\"step\", ax=axes[1, 1]).set(yscale ='log')\n",
    "\n",
    "fig.suptitle('Sentiment intensity (Vader)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d5805",
   "metadata": {},
   "source": [
    "#### Combine timeseries and videos to get ratios "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f008cd",
   "metadata": {},
   "source": [
    "For each video, we want to get the ratio of like by subscribers of the channel that uploaded the video. As well as the ratio of dislike by subscribers, and views by total views of the channel. To do this, we need to merge the timeseries dataframe and the videos features dataframe on the date, grouping them by channel id.\n",
    "\n",
    "Since we want to get the most accurate number of subscribers at the time of upload of the given video, we perform a nearest time merge, where we only merge on the entry of timeseries that has the closest datetime to the upload date, given a tolerance of one week (as the timeseries analysis was conducted per week). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc8f85",
   "metadata": {},
   "source": [
    "First step is to load the timeseries and filter out the years that are not used in our study (here we only keep 2019 for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabdaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_timeseries = pd.read_csv(\"data/df_timeseries_en.tsv\", sep=\"\\t\")\n",
    "df_timeseries_2019 = df_timeseries[pd.to_datetime(df_timeseries[\"datetime\"]).dt.year == 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8817b",
   "metadata": {},
   "source": [
    "Then, we rename the columns accordingly for the merge asof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53634cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_timeseries_2019[\"datetime\"] = pd.to_datetime(df_timeseries_2019[\"datetime\"])\n",
    "df_timeseries_2019.rename({\"datetime\": \"nearest_time\"}, axis=1, inplace=True)\n",
    "videos_features.rename({\"upload_date\": \"nearest_time\"}, axis=1, inplace=True)\n",
    "df_timeseries_2019.rename({\"channel\": \"channel_id\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e37827",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_on_date_by_channel = pd.merge_asof(videos_features.sort_values(\"nearest_time\"),df_timeseries_2019.sort_values(\"nearest_time\"),on=\"nearest_time\",by=\"channel_id\",allow_exact_matches=True,direction=\"nearest\",tolerance=pd.Timedelta(1,unit=\"W\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22d8d9",
   "metadata": {},
   "source": [
    "Since some videos were uploaded by channels that are not in the timeseries, we end up with NaN values. We decided to remove the rows that have these NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fad95d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# approx 1M missing values (channels that are in metadata but not in timeseries)\n",
    "videos_on_date_by_channel.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69b118",
   "metadata": {},
   "source": [
    "We create new columns for the ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28549086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratio_column(df, new_col,col1,col2):\n",
    "        df[new_col] = df[col1]/df[col2]\n",
    "\n",
    "create_ratio_column(videos_on_date_by_channel,\"like_count_by_subs\",\"like_count\",\"subs\")\n",
    "create_ratio_column(videos_on_date_by_channel,\"dislike_count_by_subs\",\"dislike_count\",\"subs\")\n",
    "create_ratio_column(videos_on_date_by_channel,\"view_count_by_channel_views\",\"view_count\",\"views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9622d86",
   "metadata": {},
   "source": [
    "Let's now plot the distribution of the number of views between all the videos and the distribution of the number of subscribers between all the channels. In fact, knowing this information will helps us decide what kind of normalization should be use in the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19062f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "videos_on_date_by_channel = videos_on_date_by_channel[videos_on_date_by_channel[\"views\"] > 0]\n",
    "videos_on_date_by_channel = videos_on_date_by_channel[videos_on_date_by_channel[\"subs\"] > 0]\n",
    "\n",
    "sns.histplot(videos_on_date_by_channel, x=\"views\", bins=50, element=\"step\", ax=axes[0])\n",
    "sns.histplot(videos_on_date_by_channel, x=\"subs\", bins=50, element=\"step\", ax=axes[1])\n",
    "\n",
    "axes[0].set(yscale ='log')\n",
    "axes[0].set_title('Distribution of the number of views between all the videos')\n",
    "\n",
    "axes[1].set(yscale ='log')\n",
    "axes[1].set_title('Distribution of the number of subscribers between all the channels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
